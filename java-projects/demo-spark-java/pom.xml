<project xmlns="http://maven.apache.org/POM/4.0.0"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>
	<groupId>org.demo.big.data.spark</groupId>
	<artifactId>demo-spark-java</artifactId>
	<version>0.0.1</version>
	<packaging>jar</packaging>
	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<maven.compiler.source>1.8</maven.compiler.source>
		<maven.compiler.target>1.8</maven.compiler.target>
		<spark.version>2.4.5</spark.version>
		<scala.version>2.12</scala.version>
		<mongo.spark.connector.version>2.4.1</mongo.spark.connector.version>
	</properties>
	<dependencies>
		<!-- Scala dependencies, inclusive of "hadoop-client" -->
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-sql_${scala.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.version}</artifactId>
			<version>${spark.version}</version>
			<scope>runtime</scope>
		</dependency>
		<!-- Mongo db spark connector/driver -->
		<dependency>
			<groupId>org.mongodb.spark</groupId>
			<artifactId>mongo-spark-connector_${scala.version}</artifactId>
			<version>${mongo.spark.connector.version}</version>
		</dependency>
	</dependencies>
	<build>
		<finalName>demo-spark-java</finalName>
	</build>
</project>